# Report add- 垃圾分类软件制作

- 姓名：石宇洋
- 学号：2019301660

## 任务简介

* 完成了之前的“报告”，我决定将之前**使用写过代码进行改进**，并使用Qt Designer绘制界面，使用Pyqt5制作出一个用于垃圾分类的简易界面，制作一个可以实现**“简易的垃圾分类“**功能的软件。

* 本次的报告的主要任务是制作一个款带有GUI界面的**“垃圾分类识别”**程序。程序可以实现简单的**垃圾分类识别**、网络爬取相关图片（可以当作数据集训练识别模型）、使用自带或爬取的数据集**训练识别模型**的功能，并且通过简单易懂的界面使用户易于**进行操作交互**，最大化地提供用户的使用效率。

* 本次任务使用的编程语言为Python，所使用的GUI界面辅助设计工具为Qt designer，编程环境为Anaconda文件夹envs中创建的虚拟环境，涉及到的第三方库有：os、PyQt5、sys、opencv-python、time、Pillow、numpy、tensorflow、re、requests、shutil、random。

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105102705949.png" alt="image-20220105102705949" style="zoom:20%;" />
  
  

## 软件功能简介

* 制作简易的**可交互界面**，便于使用者可以便捷操作，设定软件界面**自适应用户桌面分辨率**

* 使用者可以使用**“软件自带模型”**进行对图片的预测

* 使用者可以使用**“自己的模型”**对图片进行预测

* 使用者可以使用**“爬虫”**从网络上爬取所需要类别的图片，收集大量数据以供训练自己模型所用

* 对爬取的图片进行判定，判断其是否为**“空图片”或者“图片格式错误”**

* 使用者可以使用“爬取到的数据集”或者“自己的数据集”进行**CNN网络模型训练**并保存成.h5文件

* 使用者可以使用“爬取到的数据集”或者“自己的数据集”进行**Mobilenet网络模型训练**并保存成.h5文件

  

## 原理介绍

​		本次的训练模型采用的是卷积神经网络CNN，深度级可分离卷积网络Moblienet，后者也是近几年Google研发“轻量级”CNN，所以原理部分重点介绍这两个网络原理。

### 1.卷积神经网络介绍

​		在这一部分内容中，我打算先对**全连接神经网络原理**进行介绍，然后通过说明**全连接神经网络与卷积神经网络的差异**，进而讲解**卷积神经网络**的组成和优缺点。

#### 1.1 全连接神经网络

##### 1.1.1 神经网络简介

基于生物神经元模型可得到多层感知器，也就是MLP，其最典型结构包括三层：输入层、隐层和输出层，MLP神经网络不同层之间是全连接的，也就是说：上一层的任何一个神经元与下一层的所有神经元都有连接。这样就构成了一个全连接的神经网络，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105103206913.png" alt="image-20220105103206913" style="zoom:20%;" />

神经网络主要有三个基本要素：**权重**、**偏置**和**激活函数**。**权重**，也就是神经元之间的连接强度由权重控制，权重的大小表示可能性的大小；**偏置**，**偏置**的设置是为了正确分类样本，是模型中一个重要的参数，即保证通过输入算出的输出值不能随便激活；**激活函数**，起非线性映射的作用，其可将神经元的输出幅度限制在一定范围内，一般限制在（-1~1）或（0~1）之间，最常用的激活函数是Sigmoid函数，可将（-∞，+∞）的数映射到（0~1）的范围内。



##### 1.1.2 神经网络前向传播计算

我们可以从图上明显看出神经网络前向传播计算的简单流程。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105103404756.png" alt="image-20220105103404756" style="zoom:20%;" />

如果我们知道了全连接神经网络里面的所有节点，知道它们每个的输入x，以及对应的权重与偏置，我们就能够计算出输出的y值。

比如，这里我用公式来表示y1的计算：

![img](file:////private/var/folders/3c/b9v17tjd7z9cx52xkgw84vch0000gn/T/com.kingsoft.wpsoffice.mac/wps-rockyy/ksohtml/wpsfmqZhq.jpg) 

然后对于公式里的a可以也通过前向节点一个个进行计算,例如，

![img](file:////private/var/folders/3c/b9v17tjd7z9cx52xkgw84vch0000gn/T/com.kingsoft.wpsoffice.mac/wps-rockyy/ksohtml/wpsnpSXyB.jpg) 

​		这样，同理我们可以计算出所有节点对应的值，以及整个网络对应的输出值。另外，在计算机里面，我们通常使用数组或者矩阵的形式来定义数据，这样计算机计算速度以及效率会得到大幅度提高，所以我们也可以用**矩阵的形式**来表示我们需要处理的计算。

所以，这里神经网络前向计算就是得出我们想要结果的一个过程。



##### 1.1.3 神经网络反向传播训练

​		那么，如果我们的神经网络每个连接上的权值都知道，那么就可以将输入数据代入得到希望的结果。不过，事先我们并不知道每一个节点的参数，所以，找到这些参数，也就是我们所说的**神经网络训练过程**。神经网络是一个模型，那么这些权值就是**模型的参数**，也就是模型要学习的东西。具体的流程就是先设定误差传递函数，通过使用链式求导法则，使用随机梯度下降算法，从而反推出每个节点的系数。当然，这里在计算的时候要区分输出层与隐层，二者的数学计算公式不太一样。



#### 1.2 **卷积/全连接神经网络差异**

​		这里我我在网上找到了两张对比图，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105103634613.png" alt="image-20220105103634613" style="zoom:20%;" />

​		虽然从上图显示的两者直观上差异比较大，但是实际上他们的整体架构是相似的。全连接神经网络、卷积神经网络都是通过一层一层的节点组织起来的。不同的是，在全连接神经网络中，两层之间的节点都是全部有连接，所以一般会将每层全连接层中的节点组织成一列；而在卷积神经网络中，相邻两次之间只有部分节点相连，为了展示每一层神经元的维度，一般会将每一层卷积层的节点组织成一个三维矩阵。

​		除了结构相似，卷积神经网络的输入输出以及训练流程与全连接神经网络也基本一致。以图形分类为例，卷积神经网络的输入层就是图像的原始像素，而输出层中的每一个节点代表了不同类别的可信度。

​		不过，虽然两者十分相似，但是在实际应用上还是存在着很大的差异。比如，在使用全连接神经网络处理图像时，最大问题在于全连接层的参数太多。

​		我这里查看了Cifar-10数据集，数据集里面的图片的大小为32*32*3，其中32*32表示图片的大小，3表示RGB三通道，这样一计算，输入层的维度就是3072维度，如果第一隐层的节点数为50个，那么就算是一层神经网络，涉及到的**参数都会到达15万个**，这对于训练来说，就会造成很大的计算压力，并且还非常可能出现**过拟合**的情况，所以必须要合理减少神经网络中参数的数量。



#### 1.3 卷积神经网络介绍

​		经典的卷积神经网络一般包含：输入层、卷积层、池化层、全连接层、Softmax层。几个层之间通过不同的连接方式又可以形成不同的神经网络。这里我在网上找到了一张最原型的CNN连接图，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104039448.png" alt="image-20220105104039448" style="zoom:20%;" />

​		我们来一一了解每个层的含义：

​		1）输入层，这里我以图像处理为例，输入层一般为一个三维的数组。其中三维数组的长、宽代表了图像的大小，而三维数组的深度代表了图像的色彩通道数量。一般为灰度（1）或者RGB（3）。

​		2）卷积层，卷积层中每一个节点的输入只是上一层神经网络的一小块，这个小块常用的大小有3×3或者5×5等。卷积层的作用就是将神经网络中的每一小块进行更加深入的分析从而得到抽象程度更高的特征。所以一般来说，通过卷积层处理过的节点矩阵会变得更深，所以在上图可以看到经过卷积层之后的节点矩阵的深度会增加。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104156987.png" alt="image-20220105104156987" style="zoom:20%;" />

​		至于卷积层的处理过程，如图所示，Kernel可以将当前层神经网络的一个子节点矩阵转化为下一层神经网络上的一个单位节点矩阵。单位节点矩阵指的是一个长和宽都是1，但是深度不限的节点矩阵。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104221056.png" alt="image-20220105104221056" style="zoom:20%;" />

​		Kernel的前向传播过程就是通过左侧小矩阵中的节点计算出右侧单位矩阵中的节点的过程。这里，我分成计算一个Kernel的前向传播与移动Kernel计算当前层的前向传播。

​		**①**首先是计算一个Kernel的前向传播，这里，我们假设将一个2×2×3的矩阵通过Kernel转换成1×1×5的节点矩阵，那么我们参考全连接神经网络就总共需要2×2×3×1×1×5+5=65个，计算公式如：

![img](file:////private/var/folders/3c/b9v17tjd7z9cx52xkgw84vch0000gn/T/com.kingsoft.wpsoffice.mac/wps-rockyy/ksohtml/wpsTRKEVW.jpg) 

​		其中，i就代表节点矩阵1×1×5中的第i个，f（）为激活函数，一般使用ReLU作为激活函数。

​		**②**计算了一个Kernel的前向传播后，我们需要计算整个卷积层的前向传播。卷积层的前向传播就是通过将一个Kernle从神经网络当前层的左上角移动到右下角，并且在移动中计算每一个对应的单位矩阵得到。这里，我在网上找了个例子进行说明。如图，使用的节点矩阵深度为1。在图中展示了在3×3矩阵上使用2×2过滤器的卷积前向传播过程。在这个过程中，首先将这个过滤器用于左上角子矩阵，然后移动到左下角矩阵，再到右上角矩阵，最后到右下角矩阵。过滤器每移动一次，可以计算得到一个值（当深度为 k 时会计算出 k 个值）。将这些数值拼成一个新的矩阵，就完成了卷积层前向传播的过程。图中右侧显示了过滤器在移动过程中计算得到的结果与新矩阵中节点的对应关系。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104349015.png" alt="image-20220105104349015" style="zoom:20%;" />

​		当然在实际的过程中，我们可以看到，如果Kernel的大小不是1×1的话，卷积层前向传播得到的矩阵的尺寸要小于当前层矩阵的尺寸。所以为了避免尺寸的变化，可以在当前层矩阵的边界上加入全0填充。这样可以使得卷积层前向传播结果矩阵的大小和当前层矩阵保持一致。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104424139.png" alt="image-20220105104424139" style="zoom:20%;" />

​		除了使用全0填充，还可以通过设置过滤器移动的步长来调整结果矩阵的大小。

​		另外，在卷积神经网络中，还有一个非常重要的性质，那就是每一个卷积层中使用的过滤器中的参数都是一样的。比如以MNIST手写体数字识别为例，无论数字“1”出现在左上角还是右下角，图片的种类都是不变的。因为在左上角和右下角使用的过滤器参数相同，所以通过卷积层之后无论数字在图像上的那个位置，得到的结果都一样。

​		所以共享过滤器的参数可以使得图像上的内容不受位置的影响，而且共享每一个卷积层中过滤器中的参数可以巨幅减少神经网络上的参数。所以综合共享参数的机制，以及移动Kernel的方法，就可以计算出卷积层每一个“格子”也就是节点的取值。

​		如图，就是从网上看到的计算举例。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104451841.png" alt="image-20220105104451841" style="zoom:20%;" />



​		3）池化层，池化层神经网络不会改变三维矩阵的深度，但是它可以缩小矩阵的大小。池化层的作用是，既可以加快计算速度也有效防止过拟合问题的作用。池化层前向传播的过程也是通过移动一个类似Kernel的结构完成的，不过池化层采用更加简单的最大值或者平均值计算。使用最大值操作的池化层被称为最大池化层、使用平均值操作的池化层被称之为平均池化层。

​		与卷积层类似，也需要设定Kernel尺寸、移动步长等，不同的是唯一的区别在于卷积层使用的Kernel是横跨整个深度的，而池化层使用的Kernel只影响一个深度上的节点。所以池化层的Kernel除了在长和宽两个维度移动之外，它还需要在深度这个维度移动。

​		4）全连接层，经过多轮卷积层和池化层的处理之后，在卷积神经网络的最后一般会是由1到2个全连接层来给出最后的分类结果。经过几轮卷积层和池化层的处理之后，可以认为图像中的信息以及抽象成了信息含量更高的特征。我们可以将卷积层和池化层看出自动图像特征提取的过程。在特征提取完成之后，让然需要使用全连接层来完成分类任务。

​		值得注意的是，此时使用全连接层网络所涉及到参数就比较少了，所以，此时使用的全连接层并不会需要太多的计算力。

​		5）输出层，将结果进行分类输出。如果使用Softmax与交叉熵，可以反应出当前的对象属于每一类的概率大小。



### 2.MoblieNet介绍

#### 2.1 MobileNet意义

​		CNN对于处于深度学习模型，特别是在视觉图像处理领域，已经是取得了不错的成绩，特别是随着计算机的计算能力快速提升，为了追求分类准确度，模型深度越来越深，模型复杂度也越来越高。我们可以从ImageNet竞赛的第一名名单中发现，虽然准确率随着模型的层数有了提高，但是其算法的复杂度也变得非常复杂。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105104714647.png" alt="image-20220105104714647" style="zoom:20%;" />

​		我们可以从表中看到，到了2015年，深度残差网络ResNet的网络层数已经达到了152层，对于计算机来说，可能识别响应速度还不会太长，但是真正应用到实际的移动或者嵌入式设备，CNN等网络的运用性不强。首先是模型过于庞大，面临着内存不足的问题，其次要求低延迟、快速响应。所以尽管未来的硬件发展可能会满足CNN等大型网络的需求，但是目前来看，还是以开发轻量化模型为主。目前的研究分为两个方向：一是对训练好的复杂模型进行压缩得到小模型；二是直接设计小模型并进行训练。当然，两者的目标都是一致的，其目标在保持模型性能的前提下降低模型大小，同时提升模型速度。**MobileNet网络**是由Google提出的小巧而高效的CNN模型，在性能与响应速度之前做了折中。

​		**这里：我尝试过将CNN导入Jetson Nano以及树莓派上面进行运行，如果模型不复杂，参数不是很多，那么在这两块板子上的运行速度还是比较快的。但是当CNN网络的分类有了几十项之后，那么识别速度将会变得非常慢。经过实际的比较，一开始在电脑上识别只需要0.1秒左右的时间，但是到了Jetson Nano上识别时间需要好几秒，如果这放在现实中使用，显然是不符合实际需求的。**

​		所以，之所以MobileNet中带有Mobile一词，便是因为它可以在移动设备或者嵌入式设备上发挥出强大的功能。



#### 2.2  MobileNet简介

​		MobileNet的主要工作是用**深度级可分离卷积**替代过去的**标准卷积**来解决卷积网络的计算效率和参数量的问题。MobileNets模型基于是深度级可分离卷积，它可以将标准卷积分解成**一个深度卷积**和一个点卷积（1 × 1 Kernel）。深度卷积将每个卷积核应用到每一个通道，而1 × 1卷积用来组合通道卷积的输出。

​		我们可以先看看MobileNet的网络结构，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105105612387.png" alt="image-20220105105612387" style="zoom:16%;" />

​		可以从网络中发现，“Depthwise Conv”就是上面提到的**深度卷积**，“1 × 1 Conv”就是上面提到的**点卷积**。而“BN”代表“批规范化”，在每次随机梯度下降时，通过mini-batch来对相应的activation做规范化操作，使得结果（输出信号各个维度）的均值为0，方差为1，这样在神经网络训练时遇到收敛速度很慢时，可以尝试加入BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。

​		我们可以看看正常的CNN网络结构，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105105645610.png" alt="image-20220105105645610" style="zoom:10%;" />



​		可以从结构上发现，两者的差别就在与把经典CNN网络的**传统卷积分解为深度卷积和点卷积**。

​		至于分解的步骤，**因为涉及到大量的数学计算，所以这里我在网上找了个定性解释的图**，如图所示。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105105814307.png" alt="image-20220105105814307" style="zoom:20%;" />

​		其中(a)就是标准卷积,(b)是深度卷积,(c)是点卷积。

​		经过了对标准卷积进行分解之后，整个网络参数数量就会减少很多，参考文献得到，经过实验，MobileNet采用3×3的Kernel，一般可达8-9倍加速，而精度不损失太多。**这里，我也将与训练CNN网络一样的数据集，对MobileNet网络进行训练，并且放到Jetson Nano板子上运行，发现识别的速度的确比CNN网络要快上很多倍。**

​		当然，MobileNet的定性分析还比较好理解，但是数学推理过程还是比较复杂的，所以这里我们作为使用者，就可以直接调用Tensorflow进行MobileNet模型构建，如图所示，就是用Tensorflow的库函数进行调用创建MobileNet网络。

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20220105110005332.png" alt="image-20220105110005332" style="zoom:25%;" />





## 软件界面展示

#### **开始垃圾分类界面**

<img src="/Users/rockyy/基于TF2.4的垃圾分类/文档截图/介绍1.png" alt="介绍1" style="zoom:25%;" />

#### 爬虫与模型训练界面

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221151623882.png" alt="image-20211221151623882" style="zoom:25%;" />



## 软件功能演示

#### 1）使用者可以使用**“软件自带模型”**进行对图片的预测

* 第一步点击“从文件夹添加模型“；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221150634541.png" alt="image-20211221150634541" style="zoom:25%;" />

* 选中**“models”**中的**“软件自带“**文件夹；

<img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221150542008.png" alt="image-20211221150542008" style="zoom:25%;" />

* 点击确定后，可以在“拖选框”内看到该文件夹里有的模型；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221151032937.png" alt="image-20211221151032937" style="zoom:25%;" />

* 这里，我们选择了一个“软件自带mobilenet.h5”，可以当前选择模型处看到；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221150950785.png" alt="image-20211221150950785" style="zoom:25%;" />

* 之后，我们便可以点击选择图片，然后从本地文件里选择一张图片；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221151903450.png" alt="image-20211221151903450" style="zoom:25%;" />

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221152129700.png" alt="image-20211221152129700" style="zoom:25%;" />

* 选择图片后，我们可以在软件中看到已经载入的图片；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221152223879.png" alt="image-20211221152223879" style="zoom:25%;" />

* 现在，我们就可以点击“识别”查看结果啦。

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221152331088.png" alt="image-20211221152331088" style="zoom:25%;" />

可以看到，**软件识别用时0.11s，并且正确识别出了是“厨余垃圾-苹果”**。



#### 2）使用者可以使用**“自己的模型”**对图片进行预测

* 此功能的使用方法与**“1）使用者可以使用“软件自带模型”进行对图片的预测”**相同，只需要在选择模型时，选定成自己模型所在的那个文件夹即可。

  

#### 3）使用者可以使用**“爬虫”**从网络上爬取所需要类别的图片，收集大量数据以供训练自己模型所用

* 切换至“爬虫与模型训练“界面；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221152935185.png" alt="image-20211221152935185" style="zoom:25%;" />

* 在左方“爬取图片”中，先选择要将图片保存的路径；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221153305552.png" alt="image-20211221153305552" style="zoom:25%;" />

* 选取了存放图片的文件夹之后，我们可以从软件上看到反馈信息，软件上会**提示目前选择的保存路径**，也可以看到软件会**提示目前该文件中是否已经有分类的照片**；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221153521929.png" alt="image-20211221153521929" style="zoom:25%;" />

* 在“文本框”内输入需要爬取的图片信息；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221154020322.png" alt="image-20211221154020322" style="zoom:25%;" />

* 点击开始爬取，我们就能够在界面右下角看到爬取的进程；

  **不过这里需要注意的是，爬取的过程中软件可能由于网速问题而导致未响应，等待一会即可**。

* 爬取成功后可以看到，**右下角窗口会显示“爬取图片数量“、“爬取用时”、“删除的空白图片”。**另外，在左上角我们可以看到，当前目录已经有了我们刚才爬取的**“厨余垃圾_苹果“分类**。

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221161113350.png" alt="image-20211221161113350" style="zoom:25%;" />

* 这时，我们可以查看文件夹中爬取的图片；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221161241061.png" alt="image-20211221161241061" style="zoom:25%;" />

  可以看到，文件中已经有了我们所需要的“苹果”图样。

  

#### 4）使用者可以使用“爬取到的数据集”或者“自己的数据集”进行**CNN网络模型训练**并保存成.h5文件

* 这里，我们还是切换到“爬虫与模型训练”界面，在右边即可以选择“数据集”所在的路径；

  * Plus：在软件内部，我将划分数据集的代码（就是将数据集划分成90%的训练集，5%的验证集，5%的预测集）绑定在了这个“点击选择路径“里面，点击这个按钮，软件就会自动进行划分。另外，在划分的同时，我还设定了一个**“判断图片格式”**是否正确的代码（因为有些文件虽然后缀是.png或者.jpg，但是是打不开也预览不了的，可能会导致后期训练模型时报错）
  * 这里因为是演示，所以数据集只用了4个类别的图片

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221163902370.png" alt="image-20211221163902370" style="zoom:25%;" />

* 然后，我们可以到工程文件的目录“datasets”里面查看当前的数据集情况；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221164008895.png" alt="image-20211221164008895" style="zoom:25%;" />

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221164018728.png" alt="image-20211221164018728" style="zoom:25%;" />

  

* 之后，我们选择“模型保存路径”，这里我们就选择和“软件自带模型“同样的文件models中进行保存；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221165239298.png" alt="image-20211221165239298" style="zoom:25%;" />

* 输入“模型名称“以及”训练次数“，点击“CNN网络”后的**“开始训练”**按钮即可开始进行模型训练；

  **这里也需要注意，在训练的过程中，软件可能出现“未响应”的情况，请耐心等待即可d(^_^o)**

  右下角会展示Tensorflow的模型训练进程～

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221170254606.png" alt="image-20211221170254606" style="zoom:25%;" />

* 我们到models文件里进行查看；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221170403002.png" alt="image-20211221170403002" style="zoom:25%;" />

  可以看到模型中已经有我们刚才训练好的"CNN_test.h5"文件了(^_^)a

* 利用我们刚才训练的模型"CNN_test.h5"进行预测；

  <img src="/Users/rockyy/Library/Application Support/typora-user-images/image-20211221175947169.png" alt="image-20211221175947169" style="zoom:25%;" />



#### 5）使用者可以使用“爬取到的数据集”或者“自己的数据集”进行**Mobilenet网络模型训练**并保存成.h5文件

具体的使用方法与**“4）使用者可以使用“爬取到的数据集”或者“自己的数据集”进行CNN网络模型训练并保存成.h5文件”**一致，只需要在训练时，选择Mobilenet网络即可。



## 软件特色

* 设计了**便于交互**的GUI界面，并且界面可以**自适应用户桌面分辨率**
* 设计了多线程界面，可以在界面上实时现实终端内容，可以**实时现实“爬虫”爬取过程与模型训练过程**

用户可以直接使用已经训练好的**“软件自带模型”**进行识别

* 用户可以使用**“自己的模型”**进行识别
* 用户可以使用软件自带的**“爬虫”**从网络上爬取所需要类别的图片，收集大量数据以供训练自己模型所用
*  软件会自动对爬取的图片进行判定，判断其是否为**“空图片”或者“图片格式错误”**
* 用户可以使用“爬取到的数据集”或者“自己的数据集”**进行CNN网络模型训练**并保存成.h5文件
* 用户可以使用“爬取到的数据集”或者“自己的数据集”**进行Mobilenet网络模型训练**并保存成.h5文件



## 心得体会

​		终于到了写这一部分的时候了，心情终于能够放松一些了。本次的软件制作与界面可以说用了**非常多的时间和精力**去完成。一开始本来没有想到自己还会制作一个带有界面的软件出来，但是因为这学期的课程，让我学习到了很多有关于代码编程的知识，所以抱着提高自己代码实践为目的，打算制作一个在现阶段比较能够**”锻炼“**我的一个软件。本次的大作业我决定分为三个阶段来进行：

​		第一步：先编写基础的“机器学习”代码、“爬虫”代码、“图像识别”代码；

​		第二步：通过基础的代码来编辑界面代码；

​		第三步：排查各种bug，编写报告文档。

​		那么在完成第一步的时候，我先是将每一部分分成一个.py文件，然后对每一个子功能进行代码编写，在这一个过程中当然也遇到了很多问题，但也是学到了不少的知识，增长了不少的实战经验。因为有了**“报告三”**的基础，所以有很多功能的代码可以自己拿过来直接用，只需要自己再编写一个MobileNet网络训练模型即可。

​		不过在这个过程中也遇到一些问题：在编写“爬虫”代码时候，最开始经过多次Debug后终于可以成功地运行，当时非常开心，不过没过多久，在后续调试的过程中，发现没修改过的程序竟然开始报错了，然后在网上搜索报错的原因，发现网上都是说浏览器header没有对应上或者已经失效了，因为对于网站的架构也不是非常熟悉，所以在网上看了很多解决方法都不是很明白，而且直接使用网上的方法进行更改会发现没有作用，当时在这个问题上花了很多时间去解决，想着一个之前可以完美运行的程序为什么突然就用不了了，然后经过很长时间的解决，最后才发现是当时网络的问题，因为网络原因而导致无法在网上进行爬取。

​		另外，此次的报告让我对于文件路径又了更深刻的理解：因为本次的程序涉及到了很多需要使用文件路径的地方，比如获取图片需要路径，保存各种文件需要路径，所以这一次的大作业因为路径的原因还导致了不少的报错。比如，在使用路径时到底是该使用“绝对路径”还是“相对路径”，该使用“/”还是“\”。这一系列的有关于路径问题也是花了很多时间去认识。另外还有一个兼容性的问题就是，一开始在Macos上使用Opencv进行图片的读取时可以使用中文路径，但是在Windows上使用Opencv就不能读取有中文路径的图片，当时这个问题困扰了我很久，因为后续程序涉及的分类、识别等都需要使用中文的路径的图片，所以还很担心如果不能解决这个兼容性的问题后续程序还需要大改的问题，不过好在经过了一番查阅，找到了使用numpy对文件路径编码方式进行修改的方法，这样就完美解决了在Windows上的Opencv使用中文路径的问题，也就可以使程序按照之前预定的方式完美运行。

​		然后是第二步编写界面的代码，因为之前从来没写过界面，所以从来没有想到在已经有了功能代码的基础上，编写一个界面的代码还会花这么多时间。在这一个部分我体会最深的就是各种修复Bug与界面多线程的设计。

​		1）首先是修复各种Bug，因为制作了GUI界面，所以一旦程序运行出错或者选取文件等出错就会导致程序闪退（甚至“选文件”是点取消都会引起闪退）。这里的解决方法只能是使用大量的“try expect”语句进行修复，但是因为在测试程序的时候还是有很多没有测试到的Bug情况，所以目前的程序估计还是会有许多闪退的现象，只能是后续慢慢调试与运行来进行修复。

​		2）其次是设计程序多线程的工作。最开始设计的界面是单线程的程序，这就代表着程序在进行“爬虫”或者“模型训练”等需要花一定时间的工作时，界面就会出现“未响应”，这种“未响应”是因为程序本来应该是在循环执行界面刷新，但是因为现在有其他的工作要做，所以刷新界面的工作就会无法被执行，导致系统提醒“程序未响应”，并且也不能实时在界面上显示终端输出的内容。后来，为了解决这一个问题，我在网上也是搜寻了很大量的资料，最终找到了使用PyQt5自带的一段“阻塞函数”来处理，原理也很简单，就是“阻塞函数”会在界面执行其他命令时停止对界面的循环刷新，这样就不会导致程序出现“未响应”的情况。并且，通过解决这一个问题，界面的文本框也能实时地显示终端输出的内容，就能够在使用“爬虫”或者“模型训练”的时候，实时查看“爬虫”进度或者“模型训练”进度。



## 项目改进

​		在此次报告的最后，本来是打算将此代码放在Jetson Nano或者树莓派上进行运行，并进行实际拍照，再利用拍到实际的垃圾照片进行模型训练。不过因为疫情封宿舍的原因，最终未能取得硬件的支持，所以也算是本次大作业的一个遗憾。后续希望能够将程序放在板子上进行实地测试，而不是通过在网上找“标准图片”进行模型训练。

​		另外，程序还有可以提升的空间，后期考虑引入Opencv进行实时摄像头的拍照识别，并且将摄像头的视频流在界面上进行展示，并且在视频上通过Opencv进行区域划分，实时将分类结果显示在视频流上。目前的摄像头实时拍照代码已经写好，后续需要考虑如何在界面上显示视频流并进行实时识别处理。

​		虽然目前的程序还有些地方存在Bug以及功能性上的不足，但是我相信通过一步步打磨升级，程序还是能够获得进步，自己也能随着这个过程获得进步。

​		**总的来说**，**从现在的角度来看整个项目，经历了从头开始策划，到一步一步学习理论知识，学习代码实践，再到最终完成了一个还比较像样的成品。这样的一个“项目开发”的过程完全独立自主，让我体会到了真正想要做好一个软件的不易。不过这次的“不易”经历也让我学习到了很多有用的开发实践经验，比如对于工程文件的妥善备份保存处理、对于工程环境的配置处理、对于多系统兼容问题处理，我也相信通过这样一步步的锻炼，一定会使自己开发实践能力得到长足的提升。**

​		**最后再次感谢布老师一学期的辛苦教学，从最初的Python基础知识一直到最后神经网络，这个过程也经历和磨练了许多。还是像“报告三”总结的一样，虽然课程结束了，但是自己的代码学习之路还任重而道远，通过课程学到最重要的并不是知识，而是一种方法，如何去学习的方法，这也将伴随我以后的整个学习生涯，指导我学的更多、学的更快、学的更好～** 
